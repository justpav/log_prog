# Отчет по лабораторной работе 
## по курсу "Искусственый интеллект"

## Нейросетям для распознавания изображений


### Студенты: 

| ФИО       | Роль в проекте                     | Оценка       |
|:---------:|:----------------------------------:|:------------:|
| Черемисинов Максим [@devepodete](https://github.com/devepodete) | Вторичная обработка датасета, обучение полносвязной нейронной сети |          |
| Коростелев Дмитрий [@Dmitry4K](https://github.com/Dmitry4K) | Первичная обработка датасета |       |
| Трофимов Максим [@student31415](https://github.com/student31415) | Обучение свёрточной нейронной сети |      |

## Результат проверки

| Преподаватель     | Дата         |  Оценка       |
|:-----------------:|:------------:|:-------------:|
| Сошников Д.В. |              |     5          |

> *Правильнее было бы разбивать обучающий и тестовый датасет не случайным образом, а по людям (как MNIST)*

## Тема работы

Вариант: 3.

По заданию варианта требуется реализовать и протестировать несколько нейросетей для распознавания картинок с грустными, нейтральными и веселыми смайликами, предварительно обучив данную нейросеть на основе обучающей выборки. 

Кроме того, также требует собственноручно составить датасет из 900 объектов (смайликов), убрать различные артефакты и искажения и преобразовать картинки в удобный для обучения сети формат.


## Подготовка данных

Подготовка датасета осуществлялась в несколько этапов:
1. Рисование смайликов на разлинованной бумаге
2. Качественная фотография при помощи умного сканера Adobe Scanner
3. Первичная обработка при помощи Adobe Photoshop
    1. Увеличение контрастности, уменьшение яркости
    2. Марионеточная деформация, приведение картинки к квадратной форме
    3. Удаление линий разлиновки
    4. Масштабирование до размера 320x320 пикселей
4. Вторичная обработка при помощи библиотек  Python
    1. Перевод 3-x канальной цветовой картинки в одноканальный формат
    2. Наложение фильтра на пиксели, удаление артефактов
    3. Нарезание общей картинки на фрагменты 32x32

Далее приведем фотографии после некоторых этапов обработки

**_Пример фотографии после сканирования Adobe Scanner_**

![funny_1.PNG](/report_images/funny_1.PNG)![bored_1.PNG](/report_images/bored_1.PNG)

**_Обработка средствами Adobe Photoshop_**

![funny_1_tolearn.PNG](/report_images/funny_1_tolearn.png)![bored_1_tolearn.PNG](/report_images/bored_1_tolearn.png)

**_Обработка при помощи Python_**

![before-after.PNG](/report_images/before-after.PNG)

**_Класс для нарезания картинки на картинки меньшего размера_**

```Python
# split image to images
class Separator:
    def __init__(self):
        pass

    def split(self, image, rows: int, cols: int):
        height = len(image)
        width = len(image[0])

        im_height = height // rows
        im_width = width // cols

        res = []
        for i in range(rows):
            for j in range(cols):
                res.append(image[
                           i * im_height : (i+1) * im_height,
                           j * im_width : (j+1) * im_width
                           ])

        return np.array(res)

```

## Загрузка данных
Загрузка изображений производилась при помощи библиотеки ```opencv``` в классе ```Loader```:
```Python
class Loader:
    def __init__(self):
        pass

    def load_image(self, path: str):
        return cv2.imread(path, cv2.IMREAD_GRAYSCALE)

    def load_images(self, path: str):
        return [cv2.imread(path + os.path.sep + file, cv2.IMREAD_GRAYSCALE) for file in listdir(path)]

    def load_images_prefixed(self, path: str, prefix: str):
        return [cv2.imread(path + os.path.sep + file, cv2.IMREAD_GRAYSCALE)
                for file in listdir(path) if file.startswith(prefix)]
```

Изображения автоматически преобразуются из RGB в черно-белые при помощи модификатора ```cv2.IMREAD_GRAYSCALE```.

Для устранения дефектов в изображении руками подбирается граница серого цвета, который будет преобразован в белый и черный.
Функция для отбрасывания ненужных серых пикселей:
```Python
 def remove_grey(self, array):
     for i in range(len(array)):
         c = array[i]
         if c > self.grayBorder:
             array[i] = 255
```
Преобразование в черные пиксели происходит схожим образом.

После этого значения пикселей нормируются из диапазона [0, 255] в [0, 1] делением каждого значения на 255.

Последняя стадия обработки - разрезание картинки на 100 различных частей:
```Python
 def split(self, image, rows: int, cols: int):
     height = len(image)
     width = len(image[0])

     im_height = height // rows
     im_width = width // cols

     res = []
     for i in range(rows):
         for j in range(cols):
             res.append(image[
                        i * im_height : (i+1) * im_height,
                        j * im_width : (j+1) * im_width
                        ])

     return np.array(res)
```

## Обучение нейросети

Измерения для однослойной и многослойной полносвязных сетей производились по 5 раз, значения в таблицах - усредненные.

### Полносвязная однослойная сеть
Создание модели:
```Python
# Входной слой (размер равен размеру изображения)
inp = Input(shape=(img_size,))

# скрытые слои (в данном случае один)
hiddens = [Dense(hidden_size, activation='relu')(inp)]
while hidden_layers > 1:
  hiddens.append(Dense(hidden_size, activation='relu')(hiddens[-1]))
  hidden_layers -= 1

# выходной слой
out = Dense(num_classes, activation='softmax')(hiddens[-1])

model = Model(inputs=inp, outputs=out)

model.compile(loss='categorical_crossentropy',
            optimizer='adam',
            metrics=['accuracy'])

# обучение
model.fit(X_train, Y_train,
        batch_size=batch_size, epochs=num_epochs,
        verbose=0, validation_split=0.1)

# проверка точности на тестовом наборе
model.evaluate(X_test, Y_test, verbose=1)
```

#### Полученные результаты
Данные для обучения и тестирования используются из всех файлов.

| test part | validation part | neurons in hidden | batch size | epochs | acc | lost |
|:---------:|:--------------:|:-----------------:|:----------:|:------:|:---:|:----:|
|0.1|0.1|256|20|30|0.85|0.54|
|0.1|0.1|256|20|40|0.86|0.49|
|0.1|0.1|512|20|30|0.85|0.49|
|0.2|0.1|512|20|30|0.87|0.49|
|0.2|0.1|1024|20|30|0.86|0.53|

В среднем получаем весьма хорошую точность предсказания, в особенности учитывая небольшое количество данных. 

Данные для обучения и тестирования используются только от двух людей.
Для тестирования используются данные третьего человека.

| test el | test part | validation part | neurons in hidden | batch size | epochs | acc | lost |
|:--------:|:---------:|:--------------:|:-----------------:|:----------:|:------:|:---:|:----:|
|1|0.1|0.1|256|20|30|0.43|3.64|
|2|0.1|0.1|256|20|30|0.73|0.91|
|3|0.1|0.1|256|20|30|0.31|3.08|

Полученные результаты получились весьма ожидаемыми, поскольку у данных второго человека было меньше всего "артефактов"
(наподобие смайликов с чрезмерно большими глазами или ртами).


### Полносвязная многослойная сеть
Создание происходит таким же образом, как и в случае односвязной нейросети.

#### Полученные результаты
2 скрытых слоя. Данные для обучения и тестирования используются из всех файлов.

| test part | validation part | neurons in hidden | batch size | epochs | acc | lost |
|:---------:|:--------------:|:-----------------:|:----------:|:------:|:---:|:----:|
|0.1|0.1|512|20|30|0.86|0.77|
|0.2|0.1|512|20|30|0.84|0.87|
|0.2|0.1|1024|20|30|0.87|0.62|

Изменение количества скрытых слоев, количества нейронов и прочих параметров не дало какого-либо существенного прироста
точности предсказания или уменьшения функции ошибок.

Изменение границ для серого цвета не дало каких-либо серьезных улучшений.

### Свёрточная сеть

#### **Архитектура**
В нашей модели есть два свёрточных слоя с 32 и 64 применяемыми фильтрами соответственно. Также после каждого свёрточного слоя мы применяем субдискретизирующие слои для уменьшения размерности в 2 раза, а следовательно числа параметров в 4 раза. Дальше применяется слой flatten для дальнейшего применения обычного нейросетивого классификатора, слой dropout для отброса половины случайный параметров во избежания переобучения, а затем применяется полносвязный слой с 3мя нейронами, т.к. всего 3 класса.  

##### Создание модели:
```python
model = keras.Sequential(
      [
          keras.Input(shape=input_shape),
          layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
          layers.MaxPooling2D(pool_size=(2, 2)),
          layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
          layers.MaxPooling2D(pool_size=(2, 2)),
          layers.Flatten(),
          layers.Dropout(0.5),
          layers.Dense(num_classes, activation="softmax"),
      ]
  )
```
##### Применение модели:
```python

  model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

  model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)

  score = model.evaluate(x_test, y_test, verbose=0)
```

#### **Результаты**
Обучение производится на 2/3 данных случайно перемешанных, а тестирование на оставшейся трети. В каждой выборке одинаковое количество представителей каждого класса.

| test part | validation part | dropout rate | batch size | epochs | acc | lost |
|:---------:|:--------------:|:-----------:|:----------:|:------:|:---:|:----:|
|0.3|0.6|0.5|20|20|0.93|0.18|
|0.3|0.6|0.5|20|10|0.88|0.34|
|0.3|0.6|0.2|20|20|0.93|0.17|


## Выводы

В данной лабораторной работе мы научились обрабатывать изображения для дальнейшего обучения на них нейроных сетей, а также создавать нейронные сети с использованием фреймворка Keras. На практике убедились, что для нашего случая свёрточные сети лучше подходят для распознавания изображений. В целом, работа была сделана без каких-либо больших сложностей. Изначально было понятно, кто что делает. В достаточно короткие сроки сделали данную лабораторную работу (за сутки растянутые на 3 дня). Для повышения командной эффективности использывали общение через социальную сеть вконтакте и создание веток в git. 
